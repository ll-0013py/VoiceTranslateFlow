{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz-AL8P55kyY"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWr-uRIjilSW"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv\n",
        "!pip install requests\n",
        "!pip install pydub\n",
        "!pip install openai\n",
        "!pip install --upgrade deepl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZKF27DaiosT"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "from datetime import datetime\n",
        "import json\n",
        "from io import BytesIO\n",
        "import os\n",
        "import pytz\n",
        "import time\n",
        "\n",
        "# Third-party imports\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import drive, files\n",
        "import deepl\n",
        "from openai import OpenAI\n",
        "from pydub import AudioSegment\n",
        "import requests\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR_GS7Bmizx7"
      },
      "outputs": [],
      "source": [
        "# Change path according to directory structure\n",
        "env_path = '/content/drive/MyDrive/VoiceTranslateFlow/.env'\n",
        "load_dotenv(env_path)\n",
        "\n",
        "SPEECHFLOW_API_KEY_ID = os.getenv(\"SPEECHFLOW_API_KEY_ID\")\n",
        "SPEECHFLOW_API_KEY_SECRET = os.getenv(\"SPEECHFLOW_API_KEY_SECRET\")\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "GENNY_API_URL = os.getenv(\"GENNY_API_URL\")\n",
        "GENNY_API_KEY = os.getenv(\"GENNY_API_KEY\")\n",
        "GENNY_SPEAKER = os.getenv(\"GENNY_SPEAKER\")\n",
        "GENNY_SPEAKER_STYLE = os.getenv(\"GENNY_SPEAKER_STYLE\")\n",
        "\n",
        "DEEPL_AUTH_KEY= os.getenv(\"DEEPL_AUTH_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sFGbqzzYeEQ"
      },
      "outputs": [],
      "source": [
        "# material_path = \"\"\n",
        "\n",
        "context_path = '/content/drive/MyDrive/VoiceTranslateFlow/data/context.txt'\n",
        "prompt_fix_jp_path = '/content/drive/MyDrive/VoiceTranslateFlow/data/prompt_fix_jp.txt'\n",
        "# prompt_translation_path = '/content/drive/MyDrive/VoiceTranslateFlow/data/prompt_translation.txt'\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/VoiceTranslateFlow/output\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59kaHwdS5hZ3"
      },
      "source": [
        "# SpeechFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwPwmiq-4O5e"
      },
      "source": [
        "ref: https://docs.speechflow.io/#/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgRRO_PRlrsE"
      },
      "outputs": [],
      "source": [
        "def def_info_speechflow(material_path):\n",
        "    # SpeechFlow API key\n",
        "    # Generate API KEY, see: https://docs.speechflow.io/#/?id=generate-api-key\n",
        "\n",
        "    # The language code of the speech in media file.\n",
        "    # See more lang code: https://docs.speechflow.io/#/?id=ap-lang-list\n",
        "    global LANG\n",
        "    LANG = \"ja\"\n",
        "\n",
        "    # The local path or remote path of media file.\n",
        "    global FILE_PATH\n",
        "    FILE_PATH = material_path\n",
        "\n",
        "    # The translation result type.\n",
        "    # 1, the default result type, the json format for sentences and words with begin time and end time.\n",
        "    # 2, the json format for the generated subtitles with begin time and end time.\n",
        "    # 3, the srt format for the generated subtitles with begin time and end time.\n",
        "    # 4, the plain text format for transcription results without begin time and end time.\n",
        "    global RESULT_TYPE\n",
        "    RESULT_TYPE = 1\n",
        "\n",
        "    global headers\n",
        "    headers = {\"keyId\": SPEECHFLOW_API_KEY_ID, \"keySecret\": SPEECHFLOW_API_KEY_SECRET}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgeOHms13suX"
      },
      "outputs": [],
      "source": [
        "# Just following the Official Document\n",
        "def create():\n",
        "    create_data = {\n",
        "        \"lang\": LANG,\n",
        "    }\n",
        "    files = {}\n",
        "    create_url = \"https://api.speechflow.io/asr/file/v1/create\"\n",
        "    if FILE_PATH.startswith('http'):\n",
        "        create_data['remotePath'] = FILE_PATH\n",
        "        print('submitting a remote file')\n",
        "        response = requests.post(create_url, data=create_data, headers=headers)\n",
        "    else:\n",
        "        print('submitting a local file')\n",
        "        create_url += \"?lang=\" + LANG\n",
        "        files['file'] = open(FILE_PATH, \"rb\")\n",
        "        response = requests.post(create_url, headers=headers, files=files)\n",
        "    if response.status_code == 200:\n",
        "        create_result = response.json()\n",
        "        print(create_result)\n",
        "        if create_result[\"code\"] == 10000:\n",
        "            task_id = create_result[\"taskId\"]\n",
        "        else:\n",
        "            print(\"create error:\")\n",
        "            print(create_result[\"msg\"])\n",
        "            task_id = \"\"\n",
        "    else:\n",
        "        print('create request failed: ', response.status_code)\n",
        "        task_id = \"\"\n",
        "    return task_id\n",
        "\n",
        "\n",
        "def query(task_id):\n",
        "    query_url = \"https://api.speechflow.io/asr/file/v1/query?taskId=\" + task_id + \"&resultType=\" + str(RESULT_TYPE)\n",
        "    print('querying transcription result')\n",
        "    while (True):\n",
        "        response = requests.get(query_url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            global query_result\n",
        "            query_result = response.json()\n",
        "            if query_result[\"code\"] == 11000:\n",
        "                print('transcription result:')\n",
        "                print(query_result)\n",
        "                break\n",
        "            elif query_result[\"code\"] == 11001:\n",
        "                print('waiting')\n",
        "                time.sleep(5)\n",
        "                continue\n",
        "            else:\n",
        "                print(query_result)\n",
        "                print(\"transcription error:\")\n",
        "                print(query_result['msg'])\n",
        "                break\n",
        "        else:\n",
        "            print('query request failed: ', response.status_code)\n",
        "\n",
        "\n",
        "def speechflow(material_path):\n",
        "    print(\"\\n[Transcription started]\")\n",
        "    def_info_speechflow(material_path)\n",
        "    task_id = create()\n",
        "    if (task_id != \"\"):\n",
        "        query(task_id)\n",
        "\n",
        "\n",
        "def transcription_results(result):\n",
        "    \"\"\"Process and format transcription results.\"\"\"\n",
        "    transcription_results = []\n",
        "    sentences = json.loads(result['result'])['sentences']\n",
        "\n",
        "    # Extract each sentence's text and add it to the list\n",
        "    for sentence in sentences:\n",
        "        transcription_results.append(sentence['s'])\n",
        "\n",
        "    # Join each statement with a space and return it as a single string\n",
        "    return ' '.join(transcription_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjUVbrM_5oPv"
      },
      "source": [
        "# OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV3Xqn2b0h26"
      },
      "source": [
        "ref: https://platform.openai.com/docs/api-reference/introduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp1x_W5d0HAy"
      },
      "outputs": [],
      "source": [
        "def set_context(context_path):\n",
        "    \"\"\"Load and return the context from a file.\"\"\"\n",
        "    with open(context_path, 'r', encoding='utf-8') as file:\n",
        "        context = file.read()\n",
        "    return context\n",
        "\n",
        "\n",
        "def set_prompt(prompt_path, script_var):\n",
        "    \"\"\"Load and format the prompt with a variable.\"\"\"\n",
        "    with open(prompt_path, 'r', encoding='utf-8') as file:\n",
        "        prompt = file.read().format(script_var=script_var)\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTXwRkfOpbmi"
      },
      "outputs": [],
      "source": [
        "def chatgpt(prompt: str, context: str, api_key: str, model: str = \"gpt-4o\", max_tokens: int = 800, max_requests: int = 40) -> str:\n",
        "    \"\"\"Interact with ChatGPT API to generate a response based on prompt and context.\"\"\"\n",
        "    print(\"\\n[ChatGPT session started]\")\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    # Initialize the conversation with context and prompt\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": context},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    complete_response = \"\"\n",
        "    request_count = 0  # Counter for the number of requests\n",
        "\n",
        "    try:\n",
        "        while request_count < max_requests:  # Limit the number of requests\n",
        "            request_count += 1\n",
        "            print(f\"\\n[Request {request_count}] Sending API request...\")\n",
        "\n",
        "            # Send the API request\n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                temperature=0.3,\n",
        "                max_tokens=max_tokens\n",
        "            )\n",
        "\n",
        "            content = response.choices[0].message.content\n",
        "            complete_response += content\n",
        "\n",
        "            # Display progress\n",
        "            print(f\"[Request {request_count}] Received {len(content)} tokens.\")\n",
        "            print(f\"[Total tokens so far] {len(complete_response)} tokens collected.\")\n",
        "\n",
        "            # Check if response is complete (content length less than max_tokens)\n",
        "            if len(content) < max_tokens * 0.8:  # Likely complete if < 80% of max_tokens\n",
        "                print(f\"[Completed] Full response generated with {len(complete_response)} tokens.\")\n",
        "                break\n",
        "\n",
        "            # Add the latest response to the message history\n",
        "            messages.append({\"role\": \"assistant\", \"content\": content})\n",
        "            print(f\"[Request {request_count}] Continuing to request additional content...\")\n",
        "\n",
        "        # If loop ends due to request count limit\n",
        "        if request_count >= max_requests:\n",
        "            print(\"[Warning] Maximum request count reached, response may be incomplete.\")\n",
        "\n",
        "        return complete_response\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX0MwOCOjSVe"
      },
      "source": [
        "# Deepl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8jdSS5F0nAQ"
      },
      "source": [
        "ref: https://developers.deepl.com/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn9fQeh2jSs_"
      },
      "outputs": [],
      "source": [
        "def use_deepl(source_text):\n",
        "    print(\"\\n[Translation started]\")\n",
        "    translator = deepl.Translator(DEEPL_AUTH_KEY)\n",
        "\n",
        "    # Define maximum chunk size as 50,000 characters\n",
        "    max_chunk_size = 50000\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    translated_chars = 0  # To keep track of the total translated characters\n",
        "\n",
        "    # Split the text into chunks of 50,000 characters or less\n",
        "    while start < len(source_text):\n",
        "        # Set the end of the current chunk\n",
        "        end = min(start + max_chunk_size, len(source_text))\n",
        "\n",
        "        # Adjust end to the last period (。) within the chunk, if possible\n",
        "        if end < len(source_text) and \"。\" in source_text[start:end]:\n",
        "            end = source_text.rfind(\"。\", start, end) + 1\n",
        "        elif end == len(source_text):\n",
        "            end = len(source_text)\n",
        "\n",
        "        # Add the chunk to the list and update the starting position\n",
        "        chunks.append(source_text[start:end])\n",
        "        start = end\n",
        "\n",
        "    # Translate each chunk and combine the results\n",
        "    translated_texts = []\n",
        "    for chunk in chunks:\n",
        "        result = translator.translate_text(chunk, target_lang=\"EN-US\").text\n",
        "        translated_texts.append(result)\n",
        "\n",
        "        # Update and display progress\n",
        "        translated_chars += len(chunk)\n",
        "        print(f\"Translated {translated_chars} / {len(source_text)} characters\")\n",
        "\n",
        "    # Combine all translated chunks\n",
        "    return ''.join(translated_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9KDP6S25ffR"
      },
      "source": [
        "# Genny"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz-G43oI0rG-"
      },
      "source": [
        "ref: https://api.genny.lovo.ai/api/docs\n",
        "\n",
        "ref2: https://docs.genny.lovo.ai/reference/intro/getting-started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV_LbYBX0Xq4"
      },
      "outputs": [],
      "source": [
        "def def_header_genny():\n",
        "    # Request header\n",
        "    global HEADERS\n",
        "    HEADERS = {\n",
        "        'Accept': 'application/json',\n",
        "        'X-Api-Key': GENNY_API_KEY,\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "# Text splitting function\n",
        "def split_text(text, max_length=500):\n",
        "    \"\"\"Split text into chunks within the specified maximum length.\"\"\"\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in text.split(\". \"):\n",
        "        if len(current_chunk) + len(sentence) + 1 <= max_length:\n",
        "            current_chunk += sentence + \". \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \". \"\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Text-to-speech synthesis function\n",
        "def synthesize_text(text_chunk, chunk_index, total_chunks):\n",
        "    \"\"\"Convert a text chunk to audio using the synthesis API.\"\"\"\n",
        "    data = {\n",
        "        'text': text_chunk,\n",
        "        'speaker': GENNY_SPEAKER,\n",
        "        'speakerStyle': GENNY_SPEAKER_STYLE,\n",
        "        'speed': 1.0\n",
        "    }\n",
        "    print(f\"[{chunk_index + 1}/{total_chunks}] Synthesizing chunk...\")\n",
        "    response = requests.post(GENNY_API_URL, headers=HEADERS, json=data)\n",
        "\n",
        "    if response.status_code == 200 or response.status_code == 201:\n",
        "        response_json = response.json()\n",
        "        # Check for 'urls' key in the response; if missing, display an error\n",
        "        if \"data\" in response_json and response_json[\"data\"] and \"urls\" in response_json[\"data\"][0]:\n",
        "            audio_url = response_json[\"data\"][0][\"urls\"][0]\n",
        "            audio_response = requests.get(audio_url)\n",
        "\n",
        "            if audio_response.status_code == 200:\n",
        "                print(f\"[{chunk_index + 1}/{total_chunks}] Chunk synthesis succeeded.\")\n",
        "                return AudioSegment.from_file(BytesIO(audio_response.content), format=\"wav\")\n",
        "            else:\n",
        "                print(f\"[{chunk_index + 1}/{total_chunks}] Failed to download audio. Status code:\", audio_response.status_code)\n",
        "                return None\n",
        "        else:\n",
        "            print(f\"[{chunk_index + 1}/{total_chunks}] Audio URL not found in response. Response content:\", response_json)\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"[{chunk_index + 1}/{total_chunks}] Failed to synthesize text. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Concatenate multiple audio segments\n",
        "def concatenate_audios(audio_segments):\n",
        "    \"\"\"Concatenate multiple audio segments into one.\"\"\"\n",
        "    combined_audio = AudioSegment.empty()\n",
        "    for segment in audio_segments:\n",
        "        combined_audio += segment\n",
        "    return combined_audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hf6OrQEo1AdX"
      },
      "outputs": [],
      "source": [
        "# Main processing function\n",
        "def genny(text, current_time):\n",
        "    \"\"\"Main processing function.\"\"\"\n",
        "    print(\"\\n[Text-to-speech process started]\")\n",
        "    def_header_genny()\n",
        "\n",
        "    text_chunks = split_text(text)\n",
        "    total_chunks = len(text_chunks)\n",
        "    audio_segments = []\n",
        "    script_content_en = \"\"\n",
        "    file_index = 1  # File index number\n",
        "\n",
        "    for i, chunk in enumerate(text_chunks):\n",
        "        print(f\"Processing chunk {i + 1} of {total_chunks}\")\n",
        "\n",
        "        audio_segment = synthesize_text(chunk, i, total_chunks)\n",
        "        if audio_segment:\n",
        "            audio_segments.append(audio_segment)\n",
        "            script_content_en += f\"{chunk}\\n\\n\"  # Add successful chunk to script\n",
        "\n",
        "        else:\n",
        "            print(f\"Skipping chunk {i + 1} due to synthesis failure.\")\n",
        "\n",
        "        # Save files every 80 chunks or at the end\n",
        "        if (i + 1) % 80 == 0 or (i + 1) == total_chunks:\n",
        "            # Save audio file\n",
        "            if audio_segments:\n",
        "                combined_audio_en = concatenate_audios(audio_segments)\n",
        "                audio_filename = f\"en_audio{file_index}_{current_time}.wav\"\n",
        "                save_audio(combined_audio_en, audio_filename)\n",
        "                audio_segments = []\n",
        "\n",
        "            # Save script file\n",
        "            if script_content_en:\n",
        "                script_filename_en = f\"en_script{file_index}_{current_time}.txt\"\n",
        "                save_script(script_content_en, script_filename_en)\n",
        "                script_content_en = \"\"\n",
        "\n",
        "            file_index += 1\n",
        "            time.sleep(3)  # Wait before the next request\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dCWx0mYjiV"
      },
      "source": [
        "# Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W77qJVhM0QHM"
      },
      "outputs": [],
      "source": [
        "def check_path(material_path):\n",
        "    \"\"\"Check and confirm the file path.\"\"\"\n",
        "    print(\"Are you sure that this file path is correct?\")\n",
        "    check_path = False\n",
        "    while check_path != True:\n",
        "        check = input(\"If you want to re-enter, type q, or if you want to leave it as is, type any other key.\")\n",
        "        if check != \"q\":\n",
        "            check_path = True\n",
        "        else:\n",
        "            material_path = input(\"Please input the path of the material: \")\n",
        "    return material_path\n",
        "\n",
        "\n",
        "def save_audio(audio, filename=\"audio.wav\"):\n",
        "    \"\"\"Save the concatenated audio file.\"\"\"\n",
        "    global output_dir\n",
        "    output_dir = output_dir\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    audio.export(filepath, format=\"wav\")\n",
        "    print(f\"Audio file saved as {filepath}\")\n",
        "\n",
        "\n",
        "# Save the script text to a file\n",
        "def save_script(script, filename):\n",
        "    \"\"\"Save the script text as a file.\"\"\"\n",
        "    global output_dir\n",
        "    output_dir = output_dir\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    with open(filepath, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(script)\n",
        "    print(f\"Script file saved as {filepath}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8_t7lJpYl5n"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main function for processing transcription, fixing, translating, and generating audio.\"\"\"\n",
        "\n",
        "    # Get current timestamp\n",
        "    current_time = datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "\n",
        "    # Ask material_path\n",
        "    material_path = input(\"Please input the path of the file: \")\n",
        "    material_path = check_path(material_path)\n",
        "\n",
        "    # Transcription process\n",
        "    speechflow(material_path)\n",
        "    original_jp_text = transcription_results(query_result)\n",
        "\n",
        "    # Fix Japanese text using ChatGPT\n",
        "    context = set_context(context_path)\n",
        "    prompt_fix_jp = set_prompt(prompt_fix_jp_path, original_jp_text)\n",
        "    fixed_jp_text = chatgpt(prompt_fix_jp, context, OPENAI_API_KEY)\n",
        "\n",
        "    # Save fixed Japanese script if available\n",
        "    if fixed_jp_text:\n",
        "        script_filename_jp = f\"jp_script_{current_time}.txt\"\n",
        "        save_script(fixed_jp_text, script_filename_jp)\n",
        "\n",
        "    # Translate fixed Japanese text to English\n",
        "    en_text = use_deepl(fixed_jp_text)\n",
        "\n",
        "    # Convert English text to speech\n",
        "    genny(en_text, current_time)\n",
        "    print(\"\\nCompleted this process.\\nIf you want to run it in a different file, restart the runtime.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0C1fza2Cg6K_"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
